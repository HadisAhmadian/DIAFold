{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Scatter Plots"
      ],
      "metadata": {
        "id": "YSNLojBSdAjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEvjngWBcu9d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "files = {\n",
        "    \"O-Physico\": \"/content/strct_metrics_diamond.csv\",\n",
        "    \"N-Physico\": \"/content/strct_metrics_mmseqs.csv\",\n",
        "    \"ESMFold\": \"/content/strct_metrics_ESM.csv\",\n",
        "    \"Baseline\": \"/content/strct_metrics_SingleAF.csv\",\n",
        "    \"jackhmmer\": \"/content/merged_finalhh_with_unified.csv\"\n",
        "}\n",
        "\n",
        "key_col = \"unified_target\"\n",
        "group_col = \"unified_dataset\"\n",
        "metrics = [\"rmsd\", \"tm_score_chain1_norm\", \"Maxsub\", \"GDT_TS\", \"GDT_TA\"]\n",
        "\n",
        "names = {\n",
        "    \"rmsd\": \"RMSD\",\n",
        "    \"tm_score_chain1_norm\": \"TM-score\",\n",
        "    \"Maxsub\": \"MaxSub\",\n",
        "    \"GDT_TS\": \"GDT-TS\",\n",
        "    \"GDT_TA\": \"GDT-HA\",\n",
        "}\n",
        "\n",
        "\n",
        "dfs = {}\n",
        "for label, path in files.items():\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    dfs[label] = df\n",
        "\n",
        "\n",
        "needed = {key_col, group_col, *metrics}\n",
        "for label, df in dfs.items():\n",
        "    miss = needed - set(df.columns)\n",
        "    if miss:\n",
        "        raise ValueError(f\"{label} missing columns: {miss}\")\n",
        "\n",
        "all_groups = sorted(\n",
        "    set().union(*[set(df[group_col].dropna().unique()) for df in dfs.values()])\n",
        ")\n",
        "palette = sns.color_palette(n_colors=len(all_groups))\n",
        "palette_map = dict(zip(all_groups, palette))\n",
        "\n",
        "def plot_pairwise_scatter(dfA, dfB, labelA, labelB, metric):\n",
        "    common_df = pd.merge(\n",
        "        dfA[[key_col, group_col, metric]],\n",
        "        dfB[[key_col, group_col, metric]],\n",
        "        on=[key_col, group_col],\n",
        "        how=\"inner\",\n",
        "        suffixes=(\"_a\", \"_b\")\n",
        "    )\n",
        "\n",
        "    xcol = f\"{metric}_a\"\n",
        "    ycol = f\"{metric}_b\"\n",
        "\n",
        "    finite_vals = pd.concat([common_df[xcol], common_df[ycol]], axis=0)\\\n",
        "        .replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.scatterplot(\n",
        "        data=common_df,\n",
        "        x=xcol, y=ycol,\n",
        "        hue=group_col,\n",
        "        hue_order=all_groups,\n",
        "        palette=palette_map,\n",
        "        s=35,\n",
        "        alpha=0.85\n",
        "    )\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "\n",
        "    if len(finite_vals) > 0:\n",
        "        mn, mx = float(finite_vals.min()), float(finite_vals.max())\n",
        "        plt.plot([mn, mx], [mn, mx], linestyle=\"--\", color=\"black\", label=\"y=x\")\n",
        "\n",
        "    plt.xlabel(labelA)\n",
        "    plt.ylabel(labelB)\n",
        "    plt.title(f\"{names.get(metric, metric)}  |  {labelA} vs {labelB}\")\n",
        "    plt.legend( bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "labels = list(dfs.keys())\n",
        "for metric in metrics:\n",
        "    for labelA, labelB in combinations(labels, 2):\n",
        "        plot_pairwise_scatter(dfs[labelA], dfs[labelB], labelA, labelB, metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Violin Plots"
      ],
      "metadata": {
        "id": "A-oFnM1sdEJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "names = {\n",
        "    \"rmsd\": \"RMSD\",\n",
        "    \"tm_score_chain1_norm\": \"TM-score\",\n",
        "    \"Maxsub\": \"MaxSub\",\n",
        "    \"GDT_TS\": \"GDT-TS\",\n",
        "    \"GDT_TA\": \"GDT-HA\",\n",
        "}\n",
        "\n",
        "files = {\n",
        "    \"O-Physico\": \"/content/strct_metrics_diamond.csv\",\n",
        "    \"N-Physico\": \"/content/strct_metrics_mmseqs.csv\",\n",
        "    \"ESMFold\": \"/content/strct_metrics_ESM.csv\",\n",
        "    \"Baseline\": \"/content/strct_metrics_SingleAF.csv\",\n",
        "    \"jackhmmer\": \"/content/merged_finalhh_with_unified.csv\"\n",
        "}\n",
        "\n",
        "\n",
        "base_dir = \"\"\n",
        "\n",
        "group_col = \"unified_dataset\"\n",
        "metrics = list(names.keys())\n",
        "\n",
        "\n",
        "all_rows = []\n",
        "for method_label, fname in files.items():\n",
        "    df = pd.read_csv(f\"{base_dir}/{fname}\")\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    keep_cols = [group_col] + metrics\n",
        "    missing = set(keep_cols) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{fname} missing columns: {missing}\")\n",
        "\n",
        "    dff = df[keep_cols].copy()\n",
        "    dff[\"method\"] = method_label\n",
        "    all_rows.append(dff)\n",
        "\n",
        "big = pd.concat(all_rows, ignore_index=True)\n",
        "method_order = [\"O-Physico\", \"N-Physico\", \"Baseline\", \"ESMFold\",\"jackhmmer\"]\n",
        "\n",
        "method_palette = dict(zip(method_order, sns.color_palette(\"Set1\", n_colors=len(method_order))))\n",
        "\n",
        "\n",
        "groups = big[group_col].dropna().unique().tolist()\n",
        "groups = sorted(groups)\n",
        "\n",
        "for g in groups:\n",
        "    sub_g = big[big[group_col] == g].copy()\n",
        "\n",
        "    for metric in metrics:\n",
        "        plot_df = sub_g[[\"method\", metric]].rename(columns={metric: \"value\"}).dropna()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 4.8))\n",
        "\n",
        "        sns.violinplot(\n",
        "            data=plot_df,\n",
        "            x=\"method\",\n",
        "            y=\"value\",\n",
        "            order=method_order,\n",
        "            palette=method_palette,   # رنگ بر اساس ابزار\n",
        "            #cut=0,\n",
        "            inner=\"box\",\n",
        "            linewidth=1,\n",
        "            ax=ax,\n",
        "        )\n",
        "\n",
        "        ax.set_title(f\"{names[metric]} Distribution | {g}\")\n",
        "        ax.set_xlabel(\"\")\n",
        "        ax.set_ylabel(names[metric])\n",
        "\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "zKJNzbw1cwHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pairwise Test and Forest Plots"
      ],
      "metadata": {
        "id": "-Dd40tSadOah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Pairwise comparison of 4 structure-metric CSVs (joined on unified_target),\n",
        "split into 4 unified_dataset categories, grouped per category+target, then:\n",
        "- Wilcoxon signed-rank (paired)\n",
        "- Cohen's d (paired; dz = mean(diff)/std(diff))\n",
        "- 95% CI plot (bootstrap CI of mean paired difference)\n",
        "\n",
        "Inputs are the 4 files you uploaded. Outputs:\n",
        "- pairwise_stats.csv\n",
        "- plots/*.png  (forest plots per category × metric)\n",
        "\n",
        "Requirements:\n",
        "pip install pandas numpy scipy matplotlib\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "# ----------------------------\n",
        "# Labels (as you requested)\n",
        "# ----------------------------\n",
        "files = {\n",
        "    \"O-Physico\": \"/content/strct_metrics_diamond.csv\",\n",
        "    \"N-Physico\": \"/content/strct_metrics_mmseqs.csv\",\n",
        "    \"ESMFold\": \"/content/strct_metrics_ESM.csv\",\n",
        "    \"Baseline\": \"/content/strct_metrics_SingleAF.csv\",\n",
        "    \"jackhmmer\": \"/content/merged_finalhh_with_unified.csv\"\n",
        "}\n",
        "\n",
        "metric_labels = {\n",
        "    \"rmsd\": \"RMSD\",\n",
        "    \"tm_score_chain1_norm\": \"TM-score\",\n",
        "    \"Maxsub\": \"MaxSub\",\n",
        "    \"GDT_TS\": \"GDT-TS\",\n",
        "    \"GDT_TA\": \"GDT-HA\",  # NOTE: you wrote GDT-HA for GDT_TA; keeping exactly that label.\n",
        "}\n",
        "\n",
        "METRICS = list(metric_labels.keys())\n",
        "\n",
        "# ----------------------------\n",
        "# Paths (mounted in this environment)\n",
        "# If you run locally, replace these with your real paths.\n",
        "# ----------------------------\n",
        "mounted_paths = {\n",
        "    \"O-Physico\": \"/content/strct_metrics_diamond.csv\",\n",
        "    \"N-Physico\": \"/content/strct_metrics_mmseqs.csv\",\n",
        "    \"ESMFold\": \"/content/strct_metrics_ESM.csv\",\n",
        "    \"Baseline\": \"/content/strct_metrics_SingleAF.csv\",\n",
        "    \"jackhmmer\": \"/content/merged_finalhh_with_unified.csv\"\n",
        "}\n",
        "\n",
        "JOIN_KEY = \"unified_target\"\n",
        "CAT_COL = \"unified_dataset\"  # 4 دسته\n",
        "\n",
        "OUT_DIR = \"outputs\"\n",
        "PLOT_DIR = os.path.join(OUT_DIR, \"plots\")\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "def drop_unnamed(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed:\")].copy()\n",
        "\n",
        "def paired_cohens_dz(diff: np.ndarray) -> float:\n",
        "    \"\"\"Cohen's d for paired samples (dz).\"\"\"\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    diff = diff[np.isfinite(diff)]\n",
        "    if diff.size < 2:\n",
        "        return np.nan\n",
        "    sd = diff.std(ddof=1)\n",
        "    if sd == 0:\n",
        "        return np.nan\n",
        "    return diff.mean() / sd\n",
        "\n",
        "def bootstrap_mean_ci(diff: np.ndarray, n_boot: int = 5000, ci: float = 0.95, seed: int = 123) -> tuple[float, float]:\n",
        "    \"\"\"Bootstrap CI for mean of paired differences.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    diff = diff[np.isfinite(diff)]\n",
        "    n = diff.size\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    if n == 1:\n",
        "        return (diff[0], diff[0])\n",
        "    boots = rng.choice(diff, size=(n_boot, n), replace=True).mean(axis=1)\n",
        "    alpha = (1 - ci) / 2\n",
        "    lo = np.quantile(boots, alpha)\n",
        "    hi = np.quantile(boots, 1 - alpha)\n",
        "    return (lo, hi)\n",
        "\n",
        "def safe_wilcoxon(x: np.ndarray, y: np.ndarray):\n",
        "    \"\"\"\n",
        "    Wilcoxon signed-rank test on paired vectors x,y\n",
        "    Returns (stat, p).\n",
        "    Handles edge cases where all diffs are zero / too small.\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    mask = np.isfinite(x) & np.isfinite(y)\n",
        "    x = x[mask]\n",
        "    y = y[mask]\n",
        "    if x.size < 2:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    # If all differences are zero, wilcoxon can error depending on scipy version.\n",
        "    d = x - y\n",
        "    if np.allclose(d, 0, equal_nan=False):\n",
        "        return (0.0, 1.0)\n",
        "\n",
        "    try:\n",
        "        stat, p = wilcoxon(x, y, zero_method=\"wilcox\", correction=False, alternative=\"two-sided\", mode=\"auto\")\n",
        "        return (float(stat), float(p))\n",
        "    except Exception:\n",
        "        # fallback: drop exact-zero diffs\n",
        "        nz = ~np.isclose(d, 0)\n",
        "        if nz.sum() < 2:\n",
        "            return (np.nan, np.nan)\n",
        "        stat, p = wilcoxon(x[nz], y[nz], zero_method=\"wilcox\", correction=False, alternative=\"two-sided\", mode=\"auto\")\n",
        "        return (float(stat), float(p))\n",
        "\n",
        "def forest_plot(df_plot: pd.DataFrame, title: str, out_path: str):\n",
        "    \"\"\"\n",
        "    df_plot columns required:\n",
        "      comparison, mean_diff, ci_low, ci_high\n",
        "    \"\"\"\n",
        "    df_plot = df_plot.copy().sort_values(\"comparison\", ascending=True)\n",
        "\n",
        "    y = np.arange(len(df_plot))\n",
        "    mean = df_plot[\"mean_diff\"].to_numpy()\n",
        "    lo = df_plot[\"ci_low\"].to_numpy()\n",
        "    hi = df_plot[\"ci_high\"].to_numpy()\n",
        "    xerr = np.vstack([mean - lo, hi - mean])\n",
        "\n",
        "    plt.figure(figsize=(10, max(3.5, 0.55 * len(df_plot) + 1.5)))\n",
        "\n",
        "    plt.errorbar(\n",
        "        mean, y, xerr=xerr,\n",
        "        fmt=\"o\",\n",
        "        capsize=4,\n",
        "        color=\"black\",\n",
        "        ecolor=\"black\",\n",
        "        markeredgecolor=\"black\",\n",
        "        markerfacecolor=\"black\",\n",
        "    )\n",
        "\n",
        "\n",
        "    plt.axvline(0, linewidth=1.5, color=\"red\")\n",
        "\n",
        "    plt.yticks(y, df_plot[\"comparison\"].tolist())\n",
        "    plt.xlabel(\"Mean paired difference (A - B) with 95% CI\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Load + prepare\n",
        "# ----------------------------\n",
        "dfs = {}\n",
        "for model, path in mounted_paths.items():\n",
        "    df = pd.read_csv(path)\n",
        "    df = drop_unnamed(df)\n",
        "    missing = [c for c in [JOIN_KEY, CAT_COL] + METRICS if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"[{model}] Missing columns: {missing}\\nFound: {df.columns.tolist()}\")\n",
        "    dfs[model] = df\n",
        "\n",
        "# Group first (per category + target) then mean (in case duplicates exist)\n",
        "gdfs = {}\n",
        "for model, df in dfs.items():\n",
        "    g = (\n",
        "        df.groupby([CAT_COL, JOIN_KEY], as_index=False)[METRICS]\n",
        "          .mean(numeric_only=True)\n",
        "    )\n",
        "    gdfs[model] = g\n",
        "\n",
        "# Merge all models on [unified_dataset, unified_target]\n",
        "merged = None\n",
        "for model, df in gdfs.items():\n",
        "    tmp = df.rename(columns={m: f\"{model}__{m}\" for m in METRICS})\n",
        "    if merged is None:\n",
        "        merged = tmp\n",
        "    else:\n",
        "        merged = merged.merge(tmp, on=[CAT_COL, JOIN_KEY], how=\"inner\")\n",
        "\n",
        "if merged is None or merged.empty:\n",
        "    raise RuntimeError(\"Merged dataset is empty. Check join keys / file contents.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Pairwise stats\n",
        "# ----------------------------\n",
        "models = list(files.keys())\n",
        "pairs = list(itertools.combinations(models, 2))\n",
        "categories = sorted(merged[CAT_COL].dropna().unique().tolist())\n",
        "\n",
        "rows = []\n",
        "for cat in categories:\n",
        "    sub = merged.loc[merged[CAT_COL] == cat].copy()\n",
        "\n",
        "    for metric in METRICS:\n",
        "        for a, b in pairs:\n",
        "            col_a = f\"{a}__{metric}\"\n",
        "            col_b = f\"{b}__{metric}\"\n",
        "\n",
        "            xa = sub[col_a].to_numpy(dtype=float)\n",
        "            xb = sub[col_b].to_numpy(dtype=float)\n",
        "\n",
        "            mask = np.isfinite(xa) & np.isfinite(xb)\n",
        "            xa = xa[mask]\n",
        "            xb = xb[mask]\n",
        "\n",
        "            if xa.size == 0:\n",
        "                continue\n",
        "\n",
        "            diff = xa - xb\n",
        "            stat, p = safe_wilcoxon(xa, xb)\n",
        "            d_dz = paired_cohens_dz(diff)\n",
        "            mean_diff = float(np.nanmean(diff)) if diff.size else np.nan\n",
        "            ci_low, ci_high = bootstrap_mean_ci(diff, n_boot=5000, ci=0.95, seed=123)\n",
        "\n",
        "            rows.append({\n",
        "                \"unified_dataset\": cat,\n",
        "                \"metric\": metric,\n",
        "                \"metric_label\": metric_labels[metric],\n",
        "                \"model_A\": a,\n",
        "                \"model_B\": b,\n",
        "                \"n_pairs\": int(diff.size),\n",
        "                \"wilcoxon_stat\": stat,\n",
        "                \"wilcoxon_p\": p,\n",
        "                \"cohens_dz\": d_dz,\n",
        "                \"mean_diff_A_minus_B\": mean_diff,\n",
        "                \"ci95_low\": ci_low,\n",
        "                \"ci95_high\": ci_high,\n",
        "            })\n",
        "\n",
        "stats_df = pd.DataFrame(rows)\n",
        "out_csv = os.path.join(OUT_DIR, \"pairwise_stats.csv\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "stats_df.to_csv(out_csv, index=False)\n",
        "\n",
        "print(f\"[OK] Saved stats: {out_csv}\")\n",
        "print(stats_df.head(10).to_string(index=False))\n",
        "\n",
        "# ----------------------------\n",
        "# Plots: per category × metric (forest plot across all pairwise comparisons)\n",
        "# ----------------------------\n",
        "for cat in categories:\n",
        "    for metric in METRICS:\n",
        "        sdf = stats_df[(stats_df[\"unified_dataset\"] == cat) & (stats_df[\"metric\"] == metric)].copy()\n",
        "        if sdf.empty:\n",
        "            continue\n",
        "\n",
        "        sdf[\"comparison\"] = sdf[\"model_A\"] + \" vs \" + sdf[\"model_B\"]\n",
        "        df_plot = sdf[[\"comparison\", \"mean_diff_A_minus_B\", \"ci95_low\", \"ci95_high\"]].rename(\n",
        "            columns={\n",
        "                \"mean_diff_A_minus_B\": \"mean_diff\",\n",
        "                \"ci95_low\": \"ci_low\",\n",
        "                \"ci95_high\": \"ci_high\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        title = f\"{cat} | {metric_labels[metric]} | Pairwise mean diff (A-B) with 95% CI\"\n",
        "        out_png = os.path.join(PLOT_DIR, f\"{cat}__{metric}.png\".replace(\"/\", \"_\"))\n",
        "        forest_plot(df_plot, title=title, out_path=out_png)\n",
        "\n",
        "print(f\"[OK] Saved plots in: {PLOT_DIR}\")\n"
      ],
      "metadata": {
        "id": "P5iS_oYPdW4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HeatMaps and VIF"
      ],
      "metadata": {
        "id": "6gzshaChdllW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# === Step 0: Config ===\n",
        "file_paths = [\n",
        "    '/content/MSA_qualities_diamond.csv',\n",
        "    '/content/MSA_qualities_mmseqs.csv',\n",
        "]\n",
        "\n",
        "\n",
        "names={\"/content/MSA_qualities_diamond.csv\":\"O-Physico\"\n",
        ",\"/content/MSA_qualities_mmseqs.csv\":\"N-Physico\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "msa_features = ['NEff_id62','MeanEntropy','GapFraction','AvgIdentityToQuery']\n",
        "\n",
        "\n",
        "# === Step 1: Load & Feature Engineering ===\n",
        "def load_and_process(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.dropna()\n",
        "    df = df.dropna(axis=1, how='all')\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Step 2: Collinearity Analysis ===\n",
        "\n",
        "# 2.1 Correlation Matrix\n",
        "def compute_correlation_matrices(df):\n",
        "    pearson_corr = df[msa_features].corr(method='pearson')\n",
        "    spearman_corr = df[msa_features].corr(method='spearman')\n",
        "    return pearson_corr, spearman_corr\n",
        "\n",
        "# 2.2 VIF Calculation\n",
        "def calculate_vif(df):\n",
        "    X = df[msa_features].copy()\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data['feature'] = X.columns\n",
        "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "\n",
        "\n",
        "labels=[\"Normalized NEff\",\"Mean Entropy\",\"Gap Fraction\",\"Avg. Identity\"]\n",
        "\n",
        "# === Step 4: Visualization ===\n",
        "def plot_heatmap(corr_matrix, title):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True, xticklabels=labels,yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_file(file_path):\n",
        "    print(f\"\\n=== Analyzing: {file_path} ===\")\n",
        "    df = load_and_process(file_path)\n",
        "\n",
        "    # Step 2: Correlation Matrices\n",
        "    pearson_corr, spearman_corr = compute_correlation_matrices(df)\n",
        "    print(\"\\nPearson Correlation Matrix:\")\n",
        "    print(pearson_corr)\n",
        "    print(\"\\nSpearman Correlation Matrix:\")\n",
        "    print(spearman_corr)\n",
        "\n",
        "    # Step 2: VIF\n",
        "    vif_table = calculate_vif(df)\n",
        "    print(\"\\nVIF Table:\")\n",
        "    print(vif_table)\n",
        "\n",
        "\n",
        "    # Step 4: Plots\n",
        "    plot_heatmap(pearson_corr, f\"Pearson Correlation Heatmap | {names[file_path]}\")\n",
        "    plot_heatmap(spearman_corr, f\"Spearman Correlation Heatmap | {names[file_path]}\")\n",
        "\n",
        "\n",
        "    return pearson_corr, spearman_corr, vif_table\n",
        "\n",
        "# Main Execution\n",
        "for path in file_paths:\n",
        "    analyze_file(path)\n",
        "\n",
        "# === Interpretation Guide ===\n",
        "print(\"\"\"\n",
        "Interpretation:\n",
        "- Multicollinearity check:\n",
        "    - Pearson r > 0.8 (or < -0.8) indicates strong correlation.\n",
        "    - VIF > 5 suggests multicollinearity; consider removing the feature.\n",
        "\n",
        "- Feature-Quality Association:\n",
        "    - Higher absolute Spearman correlation with TM, GDT-TS, GDT-HA suggests stronger relevance.\n",
        "    - Feature selection recommendation based on low VIF and high correlation.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "2U8LzFLidnFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# === Step 0: Config ===\n",
        "file_paths = [\n",
        "    ['/content/MSA_qualities_diamond.csv',\n",
        "    '/content/strct_metrics_diamond.csv' ],\n",
        "\n",
        "    ['/content/MSA_qualities_mmseqs.csv',\n",
        "    '/content/strct_metrics_mmseqs.csv']\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "msa_features = ['NEff_id62','MeanEntropy','GapFraction','AvgIdentityToQuery']\n",
        "quality_scores = ['tm_score_chain1_norm', 'GDT_TS', 'GDT_TA']\n",
        "\n",
        "# === Step 1: Load & Feature Engineering ===\n",
        "def load_and_process(file_path):\n",
        "    df1 = pd.read_csv(file_path[0])\n",
        "    df2 = pd.read_csv(file_path[1])\n",
        "\n",
        "    df1 = df1.dropna(axis=1, how='all')\n",
        "    df2 = df2.dropna(axis=1, how='all')\n",
        "\n",
        "\n",
        "    merged_df = pd.merge(\n",
        "    df1,\n",
        "    df2,\n",
        "    on=\"unified_id\",\n",
        "    how=\"inner\"\n",
        "    )\n",
        "\n",
        "\n",
        "    print(merged_df.head())\n",
        "    print(\"Rows:\", merged_df.shape[0])\n",
        "    print(\"Columns:\", merged_df.shape[1])\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "# === Step 3: Correlation with Structure Quality ===\n",
        "def correlation_with_quality(df):\n",
        "    results = []\n",
        "    for feature in msa_features:\n",
        "        for score in quality_scores:\n",
        "            coef, pval = spearmanr(df[feature], df[score])\n",
        "            results.append({\n",
        "                'Feature': feature,\n",
        "                'Score': score,\n",
        "                'Spearman Correlation': coef,\n",
        "                'p-value': pval\n",
        "            })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "labels=[\"Normalized NEff\",\"Mean Entropy\",\"Gap Fraction\",\"Avg. Identity\"]\n",
        "\n",
        "labels2=[\"TM-Score\",\"GDT-TS\",\"GDT-HA\"]\n",
        "\n",
        "\n",
        "# === Step 4: Visualization ===\n",
        "def plot_heatmap(corr_matrix, title):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True,xticklabels=labels2[::-1],yticklabels=labels[::-1])\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_file(file_path):\n",
        "    print(f\"\\n=== Analyzing: {file_path} ===\")\n",
        "    df = load_and_process(file_path)\n",
        "\n",
        "\n",
        "    # Step 3: Correlation with Structure Quality\n",
        "    corr_quality_table = correlation_with_quality(df)\n",
        "    print(\"\\nSpearman Correlation with TM, GDT-TS, GDT-HA:\")\n",
        "    print(corr_quality_table)\n",
        "\n",
        "\n",
        "    # Heatmap for MSA Features vs Quality\n",
        "    pivot_table = corr_quality_table.pivot(index='Feature', columns='Score', values='Spearman Correlation')\n",
        "    plot_heatmap(pivot_table, f\"Spearman Correlation (MSA Features vs Quality) | {names[file_path[0]]}\")\n",
        "\n",
        "    return corr_quality_table\n",
        "\n",
        "# Main Execution\n",
        "for path in file_paths:\n",
        "    analyze_file(path)\n",
        "\n"
      ],
      "metadata": {
        "id": "JvaesAJhdyfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Box Plots"
      ],
      "metadata": {
        "id": "v3e7ZSpGdup_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# فایل‌ها\n",
        "# -----------------------------\n",
        "files = [\n",
        "    \"MSA_qualities_diamond.csv\",\n",
        "    \"MSA_qualities_mmseqs.csv\",\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# نام ستون‌ها (دقیقاً از فایل)\n",
        "# -----------------------------\n",
        "COL_UNIFIED = \"unified_dataset\"\n",
        "COL_NEFF = \"NEff_id62\"\n",
        "\n",
        "# رنگ ثابت برای unified_dataset ها (۳ تا)\n",
        "palette = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]\n",
        "\n",
        "# -----------------------------\n",
        "# خواندن و رسم\n",
        "# -----------------------------\n",
        "for path in files:\n",
        "    df = pd.read_csv(path)\n",
        "    file_label = os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "    df = df[[COL_UNIFIED, COL_NEFF]].dropna()\n",
        "\n",
        "    unified_order = sorted(df[COL_UNIFIED].unique())\n",
        "\n",
        "    data_for_box = [\n",
        "        df.loc[df[COL_UNIFIED] == u, COL_NEFF].values\n",
        "        for u in unified_order\n",
        "    ]\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "\n",
        "    bp = plt.boxplot(\n",
        "        data_for_box,\n",
        "        labels=unified_order,\n",
        "        patch_artist=True,   # برای رنگ دادن\n",
        "        showfliers=False     # اگر outlierها رو می‌خوای True کن\n",
        "    )\n",
        "\n",
        "    # رنگ دادن به باکس‌ها\n",
        "    for box, color in zip(bp[\"boxes\"], palette):\n",
        "        box.set_facecolor(color)\n",
        "        box.set_edgecolor(\"black\")\n",
        "        box.set_alpha(0.85)\n",
        "\n",
        "    # تنظیم ظاهر خطوط\n",
        "    for k in [\"medians\", \"whiskers\", \"caps\"]:\n",
        "        for item in bp[k]:\n",
        "            item.set_color(\"black\")\n",
        "            item.set_linewidth(1.2)\n",
        "\n",
        "    plt.ylabel(COL_NEFF)\n",
        "    plt.xlabel(COL_UNIFIED)\n",
        "    plt.title(f\"{COL_NEFF} Boxplot — {file_label}\")\n",
        "\n",
        "    plt.grid(axis=\"y\", alpha=0.25)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gH0C5Jw-doKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "7xF_zrW9d6iQ"
      }
    }
  ]
}